Day one
******************************************************************************************
Today- I set up my Github repository
This helps me - save the project, create it as a portfolio for myself as well as monitor my growth
I learnt to work with Git - or atleast understand it.
#This is because its able to detect changes I make, save them and I'm also able to experiment

I also got to get through the workflow and understand the algorithms and how everythinh ties together
#The pipelines, The ML,
Python and the libraries I need to work on as well as the software process

I also got to create folders and documentations for my projects, understanding the necessity of proper storage and breaking things down into different files

- Tomorrow is Sato, so I look forward to wireframing and designing the workflow around my software, as well as understanding how that all ties together
Then we kick off continuing learning, coding and mini-projects from Monday as I keep building.
******************************************************************************************
Day Two - Saturday3rd
Today I worked on wireframes for my videdit
- I believe I came up with a nice framework of the design, focusing on intuitive design from other softwares but adding my on touch
- I've also though of turning the multi-AI pipeline into individual features that can be used as well with pre-edited clips. Different from the single AI tools in other softwares in a way due to like:
   1. Prompt engineering - still works with a pipeline that loads the video -> extracts frames -> understand the clips -> Applies the edit based on the applied prompt through LLM
   2. Template generation - it can pre - load the already generated templates and can be re-used
   3. Brand/User optimisation - able to make suggestions and recommendations based on the users style and preferences. Pattern recognition
   4. Social optimization - Change aspect ratio for different platform distribution

Following the concept in tools for though - I also think I want to incorporate manual editing with AI aid and automation
Currently only designing for desktop but will move forward to other platforms as I move forward

For Revive Africa, 
I worked on integrating the  mission of the application to the UX/UI
 - With the help of AI, I designed a good workflow
  
         Video sections: 1. For the Story of Africa 2. For the mission of Revive africa
                            |
        Horizontal scroll - To display the themes such as decolinisation of the mind as well features - They are clickable redirecting the user
                             |
        After that - a prompt to join the commuinty that lets you sign up and create an avatar
                              |
        From there, Explore Africa taking you to an interactive map- where when you hover you can acces the different aspects of the country; culture, food, clothing etc

I'm proud of that - I believe with this I'm seeing the workflow more clearly.I'm able to understand the system and how it works

Then working on some AI agents - which I beleive will aid me in understanding pipelines and nodes as well as OOP in Python
- I look forward to building with n8n as well as through code just to learn and experiment.

Day 3
*****************************************************************************************
This was yesterday, I was not feeling well so I didn't document so here I am
1. I dealt with Python significant basics seeing that 
- Variables are significant as they are the store of the metadata for the videos.
Aspects such as frames, fps, duration, video_name, resolution are all stored in the variable, thus the significance they have to the software
- Conditionals and Loops - decision making and logic
They enable the software to make decisions and iterate over the frames enabling a decision to be made
-Functions
These form part of the pipelines. They are the nodes that are connected to create the pipelines through which the software operates
- Classes and OOP
Classes encapsulate the functions/nodes to create a system that is functional, can be edited and grown.

I'm better understanding the code logic and how things work together and I'm happy for that.
Proud of myself

I also worked with Numpy and OpenCV though not much, but the interactions has made me more aware of how video data is processed, how things work together plus the correlation between Opencv and Numpy

For Numpy,
- There are basic operations that I need to understand especially because they deal with the frame/image/video manipulation, editing, mathematical concepts(algorithmic concepts) that aid in motion detection, deyecting transitions etc
Operations such as slicing, indexing etc, all play a role in the whole process

Opencv
Deals with the reading and opening of the video, storing the frames in a list which then numpy converts into an array
It also plays a role in video editing, processing and writing, saving

These two libraries work together to perform actions on the video, that then aid in template generation